task:
  trainer:
    _target_: pangaea.engine.trainer.RegTrainer
    model: null
    train_loader: null
    optimizer: null
    lr_scheduler: null
    evaluator: null
    exp_dir: null
    device: null
    criterion: null
    n_epochs: 10
    precision: fp32
    ckpt_interval: 1
    eval_interval: 1
    log_interval: 5
    best_metric_key: MSE
    use_wandb: ${use_wandb}
  evaluator:
    _target_: pangaea.engine.evaluator.RegEvaluator
    val_loader: null
    exp_dir: null
    device: null
    use_wandb: ${use_wandb}
    inference_mode: whole
    sliding_inference_batch: 8
dataset:
  _target_: pangaea.datasets.agbd.AGBD
  dataset_name: AGBD
  root_path: /scratch/tmp.34657733.anogueira/agbd_data
  hdf5_dir: /scratch/tmp.34657733.anogueira/agbd_data
  mapping_path: /scratch/tmp.34657733.anogueira/agbd_splits
  norm_path: /scratch/tmp.34657733.anogueira/agbd_data
  version: 4
  download_url: null
  auto_download: false
  split: None
  chunk_size: 1
  years:
  - 2019
  - 2020
  img_size: 25
  multi_temporal: false
  multi_modal: true
  debug: false
  ignore_index: -1
  num_classes: 1
  classes:
  - regression
  distribution:
  - 1.0
  bands:
    optical:
    - B1
    - B2
    - B3
    - B4
    - B5
    - B6
    - B7
    - B8
    - B8A
    - B9
    - B11
    - B12
    sar:
    - HH
    - HV
  data_mean:
    optical:
    - 0.12478869
    - 0.13480005
    - 0.16031432
    - 0.1532097
    - 0.20312776
    - 0.32636437
    - 0.36605212
    - 0.3811653
    - 0.3910436
    - 0.3910644
    - 0.2917373
    - 0.21169408
    sar:
    - -10.381429
    - -16.722847
  data_std:
    optical:
    - 0.024433358
    - 0.02822557
    - 0.032037303
    - 0.038628064
    - 0.04205057
    - 0.07139242
    - 0.08555025
    - 0.092815965
    - 0.0896364
    - 0.0836445
    - 0.07472579
    - 0.05880649
    sar:
    - 8.561741
    - 8.718428
  data_min:
    optical:
    - 0.0001
    - 0.0001
    - 0.0001
    - 0.0001
    - 0.0422
    - 0.0502
    - 0.0616
    - 0.0001
    - 0.055
    - 0.0012
    - 0.0953
    - 0.0975
    sar:
    - -83.0
    - -83.0
  data_max:
    optical:
    - 1.8808
    - 2.1776
    - 2.12
    - 2.0032
    - 1.7502
    - 1.7245
    - 1.7149
    - 1.7488
    - 1.688
    - 1.7915
    - 1.648
    - 1.6775
    sar:
    - 13.329468
    - 11.688309
encoder:
  _target_: pangaea.encoders.satmae_base_encoder.SatMAE_Base
  encoder_weights: ./pretrained_models/satmae_pretrain-vit-base-e199.pth
  download_url: https://zenodo.org/records/7338613/files/pretrain-vit-base-e199.pth?download=1
  model_name: SatMAE_Base
  input_size: 96
  in_chans: 3
  embed_dim: 768
  patch_size: 8
  num_heads: 12
  depth: 12
  mlp_ratio: 4.0
  mask_ratio: 0
  channel_embed: 256
  qkv_bias: true
  input_bands:
    optical:
    - B2
    - B3
    - B4
    - B5
    - B6
    - B7
    - B8
    - B8A
    - B11
    - B12
  output_layers:
  - 3
  - 5
  - 7
  - 11
  output_dim: 2304
  pyramid_output: false
decoder:
  _target_: pangaea.decoders.upernet.RegUPerNet
  encoder: null
  finetune: ${finetune}
  channels: 512
preprocessing:
  train:
    _target_: pangaea.engine.data_preprocessor.Preprocessor
    preprocessor_cfg:
    - _target_: pangaea.engine.data_preprocessor.BandFilter
    - _target_: pangaea.engine.data_preprocessor.NormalizeMeanStd
    - _target_: pangaea.engine.data_preprocessor.ResizeToEncoder
    - _target_: pangaea.engine.data_preprocessor.HorizontalFlip
  val:
    _target_: pangaea.engine.data_preprocessor.Preprocessor
    preprocessor_cfg:
    - _target_: pangaea.engine.data_preprocessor.BandFilter
    - _target_: pangaea.engine.data_preprocessor.NormalizeMeanStd
    - _target_: pangaea.engine.data_preprocessor.ResizeToEncoder
    - _target_: pangaea.engine.data_preprocessor.HorizontalFlip
  test:
    _target_: pangaea.engine.data_preprocessor.Preprocessor
    preprocessor_cfg:
    - _target_: pangaea.engine.data_preprocessor.BandFilter
    - _target_: pangaea.engine.data_preprocessor.NormalizeMeanStd
    - _target_: pangaea.engine.data_preprocessor.ResizeToEncoder
criterion:
  _target_: torch.nn.MSELoss
lr_scheduler:
  _target_: pangaea.utils.schedulers.MultiStepLR
  optimizer: null
  total_iters: null
  lr_milestones:
  - 0.6
  - 0.9
optimizer:
  _target_: torch.optim.AdamW
  params: null
  lr: 0.0001
  betas:
  - 0.9
  - 0.95
  weight_decay: 0.05
train: true
work_dir: /cluster/scratch/anogueira/
seed: 75
use_wandb: true
wandb_run_id: 6kbjkjzx
num_workers: 16
batch_size: 128
test_num_workers: 16
test_batch_size: 128
finetune: false
ckpt_dir: null
limited_label_train: 1
limited_label_val: 1
limited_label_strategy: stratified
stratification_bins: 3
data_replicate: 1
use_final_ckpt: false
show_model: false

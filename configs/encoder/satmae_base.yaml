#CHOSEN CONFIGURATION BASED ON WEBPAGES MODEL "mae_vit_base_patch16_dec512d8b", with some changes

_target_: pangaea.encoders.satmae_base_encoder.SatMAE_Base
encoder_weights: ./pretrained_models/satmae_pretrain-vit-base-e199.pth
# URL from  https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#model-weights-1, then clicked on https://zenodo.org/records/7338613 => choose file "pretrain-vit-base-e199.pth"
download_url: https://zenodo.org/records/7338613/files/pretrain-vit-base-e199.pth?download=1

model_name: SatMAE_Base

input_size: 96    #224   # corresponds to "img_size" (inferred by looking at the code from ScaleMAE "img_size=input_size") => # from https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#pretraining-1, not DEFAULT value for the model on SatMAE GitHub (was 224 but didn't work)
in_chans: 3       # Number of groups -> see Code in SatMAE GitHub => channel_groups=((0, 1, 2, 6), (3, 4, 5, 7), (8, 9))
embed_dim: 768    # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
patch_size: 8     # from https://github.com/sustainlab-group/SatMAE?tab=readme-ov-file#pretraining-1, not DEFAULT value for the model on SatMAE GitHub (was 16 but didnt work)
num_heads: 12     # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
depth: 12         # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
mlp_ratio: 4.     # From Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub
mask_ratio: 0      # 0.75
# Further variables from Config "mae_vit_base_patch16_dec512d8b(**kwargs)" on SatMAE GitHub: (excluded all decoder related variables)
channel_embed: 256
qkv_bias: True    # ScaleMAE -> CHECK

input_bands:      # channel_groups=((0, 1, 2, 6), (3, 4, 5, 7), (8, 9)); 
#Source: From the paper https://arxiv.org/pdf/2207.08051 => "Model configuration As not all of the 13 Sentinel-2 bands may be useful, in our experiments we drop bands B1, B9 and B10, which correspond to a spatial resolution of 60m. Of the remaining 10 bands, we form three groups: (i) RGB+NIR: B2, B3, B4, B8 (ii) Red Edge: B5, B6, B7, B8A (iii) SWIR: B11, B12. We choose this grouping to ensure each group has bands of the same spatial resolution and similar wavelength (see A.2.2, A.6).""
  optical:
    - B2          # 0
    - B3          # 1
    - B4          # 2
    - B5          # 3
    - B6          # 4
    - B7          # 5
    - B8          # 6
    - B8A         # 7
    - B11         # 8
    - B12         # 9

output_layers:    # Default ones accroding to PANGAEA GitHub. 3,5,7,11
  - 3
  - 5
  - 7
  - 11


output_dim: 2304  # its embed_dim * in_chans * (1-mask_ratio) ; dimension of the embedding output by the encoder, accepted by the decoder (src: base.py)
pyramid_output: False